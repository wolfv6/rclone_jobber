* About this rclone_jobber backup script tutorial
This tutorial will guide you from setup to testing a backup script.
The final product will perform scheduled local and remote backups automatically.

Both rclone and rclone_jobber.sh are command line tools.
This tutorial assumes:
- the reader has basic command-line skills
- the computer can run shell scripts (shell scripts can run on Linux, macOS, and [[https://docs.microsoft.com/en-us/windows/wsl/about][Windows 10 wsl]])

The examples are for making backups for a home PC.
The rclone_jobber.sh and job scripts can be adapted to suit your own backup needs.

Backup trivia: the verb form to "back up" is two words, whereas the noun is "backup".

*Disclaimer:*
Some of the scripts used in this tutorial delete or overwrite data.
Unless you know exactly what you are doing, please work this tutorial on a spare computer that doesn't contain data you don't want to lose.
This tutorial and associated scripts are distributed without any warranty.
I am not responsible for any lost data.

* Table of Contents                                           :TOC_2:
- [[#about-this-rclone_jobber-backup-script-tutorial][About this rclone_jobber backup script tutorial]]
- [[#install-rclone][Install rclone]]
- [[#install-rclone_jobber][Install rclone_jobber]]
- [[#setup-test-directories-and-path-variables][Setup test directories and path variables]]
- [[#take-rclone_jobbersh-for-a-test-drive][Take rclone_jobber.sh for a test drive]]
- [[#backup-job-and-rclone_jobbersh-parameters][Backup job and rclone_jobber.sh parameters]]
  - [[#backup-job-script][Backup job script]]
  - [[#1-source][1) source]]
  - [[#2-dest][2) dest]]
  - [[#3-move_old_files_to][3) move_old_files_to]]
  - [[#4-options][4) options]]
  - [[#5-job_name][5) job_name]]
  - [[#6-monitoring_url][6) monitoring_URL]]
- [[#filter-rules][Filter rules]]
- [[#select-a-cloud-storage-provider][Select a cloud storage provider]]
- [[#configure-a-remote][Configure a remote]]
- [[#configure-a-crypt][Configure a crypt]]
- [[#schedule-backup-jobs-to-run-automatically][Schedule backup jobs to run automatically]]
- [[#logging-options][Logging options]]
  - [[#amount-of-information-logged][Amount of information logged]]
  - [[#log-file-location][Log file location]]
  - [[#linux-logging-to-varlogrclone_jobberlog][Linux logging to /var/log/rclone_jobber.log]]
  - [[#linux-logrotate][Linux Logrotate]]
  - [[#linux-log-to-systemd-journal][Linux log to systemd journal]]
- [[#example-backup-jobs][Example backup jobs]]
- [[#example-restore-data-jobs][Example restore-data jobs]]
- [[#test-backup-jobs-and-test-restore-data-jobs][Test backup jobs and test restore-data jobs]]
- [[#recovery-plan][Recovery plan]]
- [[#monitoring][Monitoring]]
  - [[#check-backups][Check backups]]
  - [[#check-recovery-plan][Check recovery plan]]
- [[#license][License]]

* Install rclone
On Debian-based Linux distributions:
: $ apt-cache policy rclone
: $ sudo apt-get install rclone

On RPM-based Linux distributions:
: $ dnf info rclone
: $ sudo dnf install rclone

Or download the latest rclone from https://rclone.org/downloads/

* Install rclone_jobber
Download or clone the [[https://github.com/wolfv6/rclone_jobber][rclone_jobber repository]] to your home directory.

This tutorial assume that the rclone_jobber directory is in your home directory.

* Setup test directories and path variables
This tutorial uses example scripts that backup a small test directory.

The [[./examples/setup_test_data_directory.sh][setup_test_data_directory.sh]] script will setup a small test directory.
It recursively deletes the ~/test_rclone_data directory and rebuilds a fresh copy.
To setup a test directory from the command line:
: $ ~/rclone_jobber/examples/setup_test_data_directory.sh

The examples directory contains all the scripts used by this tutorial.
The example scripts have path variables inside \"${}\" e.g.
: dest="${USB}/test_rclone_backup"

You can set the variables in your system's environment (recommended), or you can replace occurrences of \"${}\" with your system's paths.

The example scripts use the following environment path variables:
- HOME
- USER
- rclone_jobber
- USB

If you're on Linux, add these lines to your .bashrc file, but with your system paths:
: export rclone_jobber="/home/wolfv/rclone_jobber"
: export USB="/run/media/wolfv/USB_name"
and reload .bachrc:
: $ source ~/.bachrc

The USB is just a path name used in the examples, it doesn't actually have to be a USB drive (e.g. export USB=\"/home/wolfv/test_rclone\").

* Take rclone_jobber.sh for a test drive
Once you have the test directories and path variables setup, you can take rclone_jobber for a test drive.

Here is a minimal backup job script for rclone_jobber:
: #!/bin/sh
: 
: source="${HOME}/test_rclone_data"
: dest="${USB}/test_rclone_backup"
: 
: ${rclone_jobber}/rclone_jobber.sh "$source" "$dest"

The last line calls rclone_jobber.sh with arguments =source= and =dest=.

*Important:* Since a bad backup job can cause data loss, test first with the =--dry-run= flag to see exactly what would be copied and deleted.

Open the [[./examples/job_backup_to_USB_minimal.sh][examples/job_backup_to_USB_minimal.sh]] in your favorite [[https://en.wikipedia.org/wiki/Text_editor][text editor]] and set options to =--dry-run=:
: options="--dry-run"

Run the backup job:
: $ ~/rclone_jobber/examples/job_backup_to_USB_minimal.sh

Here are some more things you can try with rclone_jobber:
1. Open rclone_jobber.log (rclone_jobber.log is in same directory as rclone_jobber.sh) so you can see what is happening.
2. Run the backup job again, this time without =--dry-run=.
3. Inspect changes in the destination files.
4. Change some files in source:
   - delete a file
   - edit a file
   - add a file
   - move a file
   And run the backup job again.

* Backup job and rclone_jobber.sh parameters
** Backup job script
Here is an example backup job with all the rclone_jobber arguments defined:
: #!/bin/sh
: 
: source="${HOME}/test_rclone_data"
: dest="${USB}/test_rclone_backup"
: move_old_files_to="dated_files"
: options="--filter-from=${rclone_jobber}/examples/filter_rules --checksum --dry-run"
: monitoring_URL="https://monitor.io/12345678-1234-1234-1234-1234567890ab"
: 
: ${rclone_jobber}/rclone_jobber.sh "$source" "$dest" "$move_old_files_to" "$options" "$(basename $0)" "$monitoring_URL"

The last line calls rclone_jobber.sh with arguments.
=source= and =dest= are required, the remaining arguments can be \"\" or undefined.

Rclone_jobber has 6 parameters, which are described in the next 6 sections:
1) source
2) dest
3) move_old_files_to
4) options
5) job_name
6) monitoring_URL

** 1) source
=source= is the directory to back up.

Example =source= argument:
: source="/home/wolfv"

** 2) dest
Data is backed up to =destination=$dest/last_snapshot=.

Example =dest= argument for [[https://rclone.org/local/][local file system]] data storage:
: dest="/run/media/wolfv/USB/wolfv_backup"

Example =dest= for remote data storage:
: dest="onedrive_wolfv_backup_crypt:"

** 3) move_old_files_to
When a file is changed or deleted, the old version already in backup is either moved or removed.
The =move_old_files_to= parameter specifies what happens to the old files.

*** move_old_files_to=\"dated_directory\"
Argument to move deleted or changed files to a dated directory:
: move_old_files_to="dated_directory" 

Old files are moved to the dated directory in their original hierarchy.
This is makes it easy to restore a deleted sub-directory.
Also convenient to manually delete very old files e.g. delete dated directories more than a year old.
: backup
: ├── 2018-02-22_14:00:14   <<<<<<<< dated_directory contains old files
: │   └── direc1
: │       └── f1            <<<<<<<< old version of file f1 moved here on directory's date
: └── last_snapshot         <<<<<<<< last_snapshot directory contains the most recent backup
:     └── direc1
:         └── f1

*** move_old_files_to=\"dated_files\"
Argument to move old files to old_files directory, and append move date to file names:
: move_old_files_to="dated_files"

Old files are moved to the old_files directory in their original hierarchy.
This is makes it easy to browse a file's history, and restore a particular version of a file.
: backup
: ├── last_snapshot         <<<<<<<< last_snapshot directory contains the most recent backup
: │   └── direc1
: │       └── f1
: └── old_files             <<<<<<<< old_files directory contains old dated_files
:     └── direc1
:         ├── f1_2018-02-22_14:00:14  <<<<<<<<< old version of file f1 moved here on appended date
:         └── f1_2018-02-22_15:00:14

*** move_old_files_to=\"\"
Argument to remove old files from backup:
: move_old_files_to=""

Only the most recent version of each file remains in the backup.
This can save a little storage space.
: backup
: └── last_snapshot         <<<<<<<< last_snapshot directory contains the most recent backup
:     └── direc1
:         └── f1            <<<<<<<< old versions of file f1 are overwritten or removed

** 4) options
The =options= argument can contain any number of rclone options.
You can put any [[https://rclone.org/docs/#options][rclone options]] in the options argument, except for these four:
: --backup-dir
: --suffix
: --log-file
: --log-level

The those options are set in rclone_jobber.sh.

Example options argument containing three rclone options:
: options="--filter-from=filter_rules --checksum --dry-run"

Rclone options used in this tutorial are:
: --filter-from  (discussed in the "filter rules" section)
: --checksum
: --dry-run

** 5) job_name
The =job_name= argument specifies the job's file name:
: job_name="$(basename $0)"

The shell command \"$(basename $0)\" will fill in the job's file name for you.

Rclone_jobber guards against =job_name= running again before the previous run is finished.
If rclone_jobber is called directly (from a job scheduler or command line without a job file), the guard will not work.

Rclone_jobber prints =job_name= in warnings and log entries.
If the =job_name= argument is undefined, then the origin of the job will be missing from the warnings and log entries.

** 6) monitoring_URL
The =monitoring_URL= argument specifies a ping URL for a cron-monitoring service.
=monitoring_URL= is optional, and no two jobs should share the same =monitoring_URL=.

Example =monitoring_URL=:
: monitoring_URL="https://monitor.io/12345678-1234-1234-1234-1234567890ab"

Every time rclone_jobber.sh completes a job without error, it pings the monitoring_URL.
If the cron monitoring service hasn't been pinged within a set amount of time, then it sends you an email alert.
Many cron monitoring services offer free plans.

Some remote data-storage providers offer an integrated monitoring service, in which case =monitoring_URL= is not needed.

* Filter rules
Filter rules tell rclone which files to include or exclude.
Open the [[./examples/filter_rules_exc][examples/filter_rules_exc]] file.
Each rule starts with a "+ " or "- ", followed by a pattern.
: A leading "+" means include if the pattern matches.
: A leading "-" means exclude if the pattern matches.

Rclone has a sophisticated set of [[https://rclone.org/filtering/][filter rules]].
For each file, the rules are processed in the order that they are defined.
If the matcher fails to find a match after testing all the filter rules, then the path is included.

In the example filter_rules_exc file, each section starts with a ###### heading ######.
The sections alternate between include and exclude, progressing from fine to coarse grained.
This example has four sections, but any number of sections are possible.
[[filter_rules][examples/filter_rules]] has two sections.

The filter_rules_exc file is specified in the rclone_jobber =options= argument like this:
: options="--filter-from filter_rules_exc"

To see the example filter_rules_exc file in action, run:
: $ ~/rclone_jobber/examples/clear_USB_test_backup.sh
: $ ~/rclone_jobber/examples/job_backup_to_USB_exc.sh

* Select a cloud storage provider
All the rclone cloud-storage providers are listed on https://rclone.org/.
Some of the cloud-storage-provider features are listed in two tables on https://rclone.org/overview/.

* Configure a remote
Once you have an account with your chosen cloud-storage provider, the next step is to configure its remote.
Configuring a remote in rclone is surprisingly straightforward for the amount of under-the-covers authentication it does.

There is one page of configuration instructions for each cloud-storage provider.
Links to the configuration instructions are at https://rclone.org/docs/#configure and https://rclone.org/.
Follow the instructions to configure your remote now, we will test the remote at the end of this section.

Rclone stores all the configuration information you entered in the default location ~/.config/rclone/rclone.conf.
The remote's password is stored in the rclone.conf file, so be careful about giving people access to it.

To list all your rclone remotes:
: $ rclone listremotes

You can set the "remote" variable in your system's environment (recommended), or you can manually replace occurrences of \"${remote}\" with your remote path.

If you're on Linux, add this line to your .bashrc file, but with your remote path:
: export remote="onedrive_test_rclone_backup"
and reload .bachrc:
: $ source ~/.bachrc

To test your remote, run:
: $ ~/rclone_jobber/examples/job_backup_to_remote.sh

* Configure a crypt
"crypt" is a kind of remote that:
- encrypts and decrypts the data stream for an underlying remote
- performs encryption and decryption on client side
- uses the same command interface as other kinds of remotes

Instructions for configuring a crypt remote are at https://rclone.org/crypt/ and https://rclone.org/docs/#configuration-encryption.

When configuring a crypt remote, rclone will ask you to give it a name.
Put some thought into naming your remotes.
In the following example, the crypt remote name is a concatenation of its underlying remote name and source-folder name:
: name> myremote_myfolder_crypt

And then rclone will ask for the name of an underlying remote:
: remote> myremote:myfolder
You can always rename a remote later via rclone config.

To list all your rclone remotes:
: $ rclone listremotes

Most remote cloud-storage providers allow you to view your directory names and file names in a web browser.
But that's not very useful if the directory and file names were encrypted by rclone.
Use rclone to browse encrypted directory and file names.

To list directories in remote:
: $ rclone lsd remote:
: $ rclone lsd remote:path

To list objects and directories of path (requires rclone-v1.40 or later):
: $ rclone lsf remote:path

To list top-level files in path:
: $ rclone ls remote:path --max-depth 1 

To list all files in path recursively:
: $ rclone ls remote:path

[[./examples/job_backup_to_remote.sh][/examples/job_backup_to_remote.sh]] uses a remote, which could be of type crypt.

To test your crypt remote, set the path variable as described in the "[[*Configure a remote][Configure a remote]]" section, and then run:
: $ ~/rclone_jobber/examples/job_backup_to_remote.sh

*** pathIsTooLong error
Most cloud storage providers have a 254 character-path-length limit.
Crypt limits encrypted paths to 151 characters with some cloud storage providers (this is a [[https://github.com/ncw/rclone/issues/637][known crypt issue]]).
If the path is too long, rclone returns this ERROR:
: Failed to copy: invalidRequest: pathIsTooLong: Path exceeds maximum length

There are 3 work-a-rounds:
- turn off "enrcrypt directory names" in rclone config (file content can still be encrypted)
- shorten your paths
- Long Path Tool (I have not tried this)

*** Backblaze b2 lifecycle
rclone crypt file-name and directory-name encryption don’t work with Backblaze b2 lifecycle because:
- b2 lifecycle appends date to end of file names
- b2 doesn’t strip off the appended date before passing the file name back to rclone

So then rclone can’t decrypt the file names.

There are 3 work-a-rounds:
- turn off "enrcrypt file names" and "enrcrypt directory names" in rclone config (file content can still be encrypted)
- turn off b2 lifecycle, set move_old_files_to=\"dated_directory\" in backup job,
  and manually delete old files at end of life
- use a different remote data-storage provider

* Schedule backup jobs to run automatically
After the backup jobs are scheduled, you will have an automated back up system that follows this workflow:
1. a job scheduler calls a backup job script
2. the job script calls rclone_jobber.sh
3. rclone_jobber.sh calls rclone
4. rclone consults your filter rules, connects to a backup storage, and uploads your data

Schedule your backup jobs in your favorite job scheduler.

The following example schedules jobs on cron (cron is a job scheduler installed on Linux).
The first line runs a local job every hour on the hour.
The second line runs a remote job every hour, 30 minutes past the hour.
: $ crontab -e
: 00 * * * * /home/wolfv/rclone_jobber/job_backup_to_USB.sh
: 30 * * * * /home/wolfv/rclone_jobber/job_backup_to_remote.sh

The initial backup will take a long time (subsequent backups are much shorter).
If your computer goes to sleep while a backup is in progress, the backup will not finish.
Consider disabling sleep on your computer.
On Linux Gnome desktop:
: right click > Settings > Power > Automatic suspend: Off

* Logging options
You can skip this section if you like the default logging.
The default behavior is to place rclone_jobber.log in the same directory as rclone_jobber.sh.

Logging options are headed by "#set log" comments in rclone_logger.sh, with a variable set to default value on the following line.
You can change the values to non-default values.

** Amount of information logged
To change amount of information logged, look for these "#set log" comments in rclone_jobber.sh:
: #set log_level for desired amount of information in rclone log entries
: #set logging to verbose

** Log file location
In rclone_jobber.sh, variable log_file contains the log file's path.
The default behavior is to place rclone_jobber.log in the same directory as rclone_jobber.sh.
You can change log_file to any path you like.
: #set log_file path
: path="$(realpath $0)"           #log file in same directory as this script
: log_file="${path%.*}.log"       #replace this file's extension with "log"

** Linux logging to /var/log/rclone_jobber.log
To set the rclone_jobber log location to /var/log/, create the log file and give it the user's ownership and read-write permission.
In this example, rclone_jobber.log ownership is given to wolfv:
: $ sudo touch       /var/log/rclone_jobber.log
: $ sudo chown wolfv /var/log/rclone_jobber.log
: $ sudo chmod 0666  /var/log/rclone_jobber.log
: $ sudo ls -l       /var/log/rclone_jobber.log
: -rw-rw-rw-. 1 wolfv root 19 Mar 21 13:58 /var/log/rclone_jobber.log

In rclone_jobber.sh, set the new log_file path:
: #set log_file path
: log_file="/var/log/rclone_jobber.log"

** Linux Logrotate
Over time a log file can grow to unwieldy size.
The logrotate utility can automatically archive the current log, start a fresh log, and delete older logs.

All you have to do is setup /var/log/rclone_jobber.log (described in previous section) and create a logrotate configuration file.
Here is creating a logrotate configuration file:
: $ sudo vi /etc/logrotate.d/rclone_jobber

And insert text something like this:
: /var/log/rclone_jobber.log {
: monthly
: rotate 2
: size 1M
: compress
: delaycompress
: }

More options are listed in man:
: $ man logrotate

Execute a dry-run to see what logrotate would do:
: $ logrotate -d /etc/logrotate.d/rclone_jobber

** Linux log to systemd journal
Linux and macOS can send all log output to systemd journal.
All you have to do is setup /var/log/rclone_jobber.log (described in section "[[*Logging to Linux /var/log/rclone_jobber.log][Logging to Linux /var/log/rclone_jobber.log]]") and make these 3 changes to rclone_jobber.sh script:
: #set log_file path
: log_file="/var/log/rclone_jobber.log"
: 
: #set log_option for rclone
: log_option="--syslog"
: 
: ...
: 
: #set log - send msg to log
: printf "$msg" | systemd-cat -t RCLONE_JOBBER -p info   #send msg to systemd journal

* Example backup jobs
The following system uses two backup jobs with complementary attributes (this is how I backup my home PC).
The latest snapshot can be easily restored from either backup.

[[./examples/job_backup_to_USB.sh][examples/job_backup_to_USB.sh]] has attributes that make it convenient to browse file history:
- local storage (for fast navigation)
- move_old_files_to=\"dated_files\" (old versions of a file are grouped together)
- not encrypted (brows files in a file manager) (unecrypted local storage is OK if storage is safe from theft, and useful if the remote storage password is lost)
- schedule hourly, on the hour (this assumes the USB drive is always plugged in and mounted)

[[./examples/job_backup_to_remote.sh][/examples/job_backup_to_remote.sh]] has attributes that make it secure, and easy to restore a deleted sub-directory:
- remote storage (off site is safe from on-site disaster)
- move_old_files_to=\"dated_directory\" (easy to restore a deleted sub-directory e.g. Documents)
- encrypted (please keep your password in a safe place)
- schedule hourly, 30 min past the hour (for a back up every 30 minutes when combined with job_backup_to_USB.sh)

In addition, job_backup_recovery_plan_to_remote.sh stores recovery-plan files off-site unecrypted.
Recovery-plan files are listed in the "[[*Recovery plan][Recovery plan]]" section.

* Example restore-data jobs
Here are three ways to restore data:
- [[./examples/job_restore_last_snapshot.sh][examples/job_restore_last_snapshot.sh]]
- [[./examples/job_restore_directory_from_remote.sh][examples/job_restore_directory_from_remote.sh]]
- use a file manager to copy a single file from local backup

* Test backup jobs and test restore-data jobs
It's human nature to neglect data recovery until it's too late.
Better to test your entire data recovery system end to end, testing both the data backup and data recovery together.
The following commands test the example backup and restore jobs.
Don't worry, the tutorial's environment is setup to make testing painless.

Previous tests modified the test directories.
Clear and setup test directories in preparation for a new test run:
: $ ~/rclone_jobber/examples/clear_USB_test_backup.sh
: $ ~/rclone_jobber/examples/clear_remote_test_backup.sh
: $ ~/rclone_jobber/examples/setup_test_data_directory.sh

Back up data:
: $ ~/rclone_jobber/examples/job_backup_to_USB.sh
: $ ~/rclone_jobber/examples/job_backup_to_remote.sh

Open job_restore_last_snapshot.sh and edit source variable to restore data from, and save your edit.
Then restore data:
: $ ~/rclone_jobber/examples/job_restore_last_snapshot.sh

Verify that the files were faithfully restored:
: $ diff -r ${HOME}/test_rclone_data/direc0 /home/${USER}/last_snapshot/direc0

Notice that rclone does not back up empty directories.

Follow a similar procedure when you practice your recovery plan, but with real data.

* Recovery plan
Example recovery plan:
1. Retrieve recovery-plan files from on-site or off-site location
   - notes for installing OS
   - recovery plan (this file)
   - job_restore_last_snapshot.sh
   - ~/.config/rclone/rclone.conf
2. Install OS
3. Install rclone
4. Restore ~/.config/rclone/rclone.conf
5. Edit source variable in job_restore_last_snapshot.sh, and then run job_restore_last_snapshot.sh

The rclone.conf configuration file should be in a secure location because it contains the encryption key for backup.
I keep my backup rclone.conf in a password manager (LastPass).
The other recovery-plan files (listed in item 1.) are not encrypted so that they can be accessed before the OS or rclone are installed.
With this setup, all I need to bootstrap the recovery process is a web browser and my LastPass master password.

Here is how to setup the recovery-plan files for easy access.
For each backup location, place the recovery-plan files in a directory to be backed up.
- If a backup is not encrypted, then the recovery-plan files will be accessible in the backup.
- If a backup is encrypted, create an unecrypted backup job to the same underlying remote, like this example:
  [[rclone_jobber/examples/job_backup_recovery_plan_to_remote.sh][job_backup_recovery_plan_to_remote.sh]] and [[rclone_jobber/examples/filter_rules_recovery_plan][filter_rules_recovery_plan]].
  And schedule the job to insure that your backup-recovery-plan files are always up-to date.

That way the recovery-plan files are with the backups, and accessible without rclone.

Practice the recovery plan.
Start from scratch with a blank environment (or use a different location on current machine).
You’ll run into snags, and that is the point.  Workout the snags BEFORE data is lost.
If you have enough disk space, restore all your data to a different directory, and then use diff to verify the accuracy of the restored data.

* Monitoring
** Check backups
Example monthly backup check.

For each backup job:
- check that recently changed files are in the backup
:    $ rclone lsl onedrive_wolfv_backup_crypt:last_snapshot/Documents/tasks --max-depth 1
:    $ ls -l /run/media/wolfv/Fedora/wolfv_backup/last_snapshot/Documents/tasks/tasks.org
- check space usage and available space
- check rclone_jobber.log
:    $ cat /var/log/rclone_jobber.log
- make sure monitoring URLs are still active

Do not rely solely on warning messages or rclone_jobber.log for monitoring; they do not prove that data was saved to destination.
Check the actual backup.

** Check recovery plan
Example yearly recovery-plan check:
1. review your recovery plan
2. make sure the recovery-plan files are still accessible and up-to date (the 4 files listed in "[[*Recovery plan][Recovery plan]]" section)
   - on site copy
   - off site copy
3. practice restore-data on small test directory, from ~/rclone_jobber/examples:
    1) setup_test_data_directory.sh
    2) job_backup_to_USB.sh
    3) job_backup_to_remote.sh
    4) delete the ~/test_data_directory
    5) job_restore_last_snapshot.sh

* License
[[http://creativecommons.org/licenses/by-nc-sa/4.0/][https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png]]\\
rclone_jobber_tutorial.org by Wolfram Volpi is licensed under a [[http://creativecommons.org/licenses/by-nc-sa/4.0/][Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License]].
Based on a work at https://github.com/wolfv6/rclone_jobber.
Permissions beyond the scope of this license may be available at https://github.com/wolfv6/rclone_jobber/issues.

Rclone_jobber is not affiliated with rclone.
