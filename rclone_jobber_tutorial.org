* About this rclone_jobber backup script tutorial
This tutorial shows you how to setup and test the rclone_jobber backup script.
The final product will perform local and remote backups automatically.

Both rclone and rclone_jobber.sh are command line tools.
This tutorial assumes:
- the reader has basic command-line skills
- the computer can run shell scripts (shell scripts can run on Linux, macOS, and [[https://docs.microsoft.com/en-us/windows/wsl/about][Windows 10 wsl]])

The examples make backups for a home PC.
The rclone_jobber.sh and its job scripts can be adapted to suit your own backup needs.

Backup trivia: the verb form to "back up" is two words, whereas the noun is "backup".

*Disclaimer:*
Some of the scripts used in this tutorial delete or overwrite data.
Unless you know exactly what you are doing, please work this tutorial on a spare computer that doesn't contain data you don't want to lose.
This tutorial and associated scripts are distributed without any warranty.
I am not responsible for any lost data.

* Table of Contents                                           :TOC_2:
- [[#about-this-rclone_jobber-backup-script-tutorial][About this rclone_jobber backup script tutorial]]
- [[#install-rclone][Install rclone]]
- [[#install-rclone_jobber][Install rclone_jobber]]
- [[#setup-test-directories-and-path-variables][Setup test directories and path variables]]
- [[#take-rclone_jobbersh-for-a-test-drive][Take rclone_jobber.sh for a test drive]]
- [[#backup-job-and-rclone_jobbersh-parameters][Backup job and rclone_jobber.sh parameters]]
  - [[#backup-job-script][Backup job script]]
  - [[#1-source][1) source]]
  - [[#2-dest][2) dest]]
  - [[#3-move_old_files_to][3) move_old_files_to]]
  - [[#4-options][4) options]]
  - [[#5-job_name][5) job_name]]
  - [[#6-monitoring_url][6) monitoring_URL]]
- [[#filter-rules][Filter rules]]
- [[#select-a-cloud-storage-provider][Select a cloud storage provider]]
- [[#configure-a-remote][Configure a remote]]
- [[#configure-a-crypt][Configure a crypt]]
- [[#schedule-backup-jobs-to-run-automatically][Schedule backup jobs to run automatically]]
- [[#logging-options][Logging options]]
  - [[#-set-logging-to-verbose][# set logging to verbose]]
  - [[#-set-log_file-path][# set log_file path]]
  - [[#-set-log_file-path-to-varlogrclone_jobberlog-linux][# set log_file path to /var/log/rclone_jobber.log (Linux)]]
  - [[#logrotate-varlogrclone_jobberlog-linux][Logrotate /var/log/rclone_jobber.log (Linux)]]
  - [[#send-varlogrclone_jobberlog-to-systemd-journal-linux][Send /var/log/rclone_jobber.log to systemd journal (Linux)]]
- [[#example-backup-jobs][Example backup jobs]]
- [[#example-restore-data][Example restore-data]]
- [[#test-backup-jobs-and-test-restore-data-jobs][Test backup jobs and test restore-data jobs]]
- [[#recovery-plan][Recovery plan]]
- [[#monitoring][Monitoring]]
  - [[#check-backups][Check backups]]
  - [[#check-recovery-plan][Check recovery plan]]
- [[#license][License]]

* Install rclone
Install the latest rclone from https://rclone.org/downloads/ 

* Install rclone_jobber
Download or clone the [[https://github.com/wolfv6/rclone_jobber][rclone_jobber repository]] to your home directory.

This tutorial assume that the rclone_jobber directory is in your home directory.

* Setup test directories and path variables
This tutorial uses example scripts that backup a small test directory.

The [[./examples/setup_test_data_directory.sh][setup_test_data_directory.sh]] script will setup a small test directory.
It recursively deletes the ~/test_rclone_data directory and rebuilds a fresh copy.
To setup a test directory from the command line:
: $ ~/rclone_jobber/examples/setup_test_data_directory.sh

The "examples" directory contains all the scripts used by this tutorial.
Most tutorials use <value> notation to indicate substitution.
This tutorial uses path variables $rclone_jobber and $usb e.g.:
: options="--filter-from=$rclone_jobber/examples/filter_rules"
: dest="$usb/test_rclone_backup"
You can automate the substitution of path variables from your .profile.
There is no need to edit the scripts.

If you're on Linux, add these lines to your ~/.profile file, but with your system paths:
: export rclone_jobber="/home/wolfv/rclone_jobber"
: export usb="/media/wolfv/USB_device_name"
and reload .profile:
: $ source ~/.profile

The "usb" is just a variable name used in the examples, it doesn't actually have to be a USB drive.
For example:
: export usb="/home/wolfv/test_rclone"

If you don't edit your .profile, you can edit the example scripts:
 replace occurrences of "$rclone_jobber" and "$usb" with your system's paths.

The example scripts use the following environment path variables:
- HOME
- USER
- rclone_jobber
- usb
- remote (explained in "Configure a remote" section)

* Take rclone_jobber.sh for a test drive
Once you have the test directories and path variables setup, you can take rclone_jobber for a test drive.

Here is a minimal backup-job script for rclone_jobber:
: #!/usr/bin/env sh
: 
: source="$HOME/test_rclone_data"
: dest="$usb/test_rclone_backup"
: 
: $rclone_jobber/rclone_jobber.sh "$source" "$dest"

The last line calls rclone_jobber.sh with arguments =source= and =dest=.

Open the [[./examples/job_backup_to_USB_minimal.sh][examples/job_backup_to_USB_minimal.sh]] in your favorite [[https://en.wikipedia.org/wiki/Text_editor][text editor]] and set options to =--dry-run=:
: options="--dry-run"

Run the backup job:
: $ ~/rclone_jobber/examples/job_backup_to_USB_minimal.sh

Here are some more things you can try with rclone_jobber:
1. Open rclone_jobber.log (rclone_jobber.log is in same directory as rclone_jobber.sh).
2. Run the backup job again, this time without =--dry-run=.
3. Inspect changes in the destination files.
4. Change some files in source:
   - delete a file
   - edit a file
   - add a file
   - move a file
   And run the backup job again.

*Important:* Since a bad backup job can cause data loss, first test with the =--dry-run= flag to see exactly what would be copied and deleted.

* Backup job and rclone_jobber.sh parameters
** Backup job script
Here is an example backup job with all the rclone_jobber.sh arguments defined:
: #!/usr/bin/env sh
: 
: source="$HOME/test_rclone_data"
: dest="$usb/test_rclone_backup"
: move_old_files_to="dated_files"
: options="--filter-from=$rclone_jobber/examples/filter_rules --checksum --dry-run"
: monitoring_URL="https://monitor.io/12345678-1234-1234-1234-1234567890ab"
: 
: $rclone_jobber/rclone_jobber.sh "$source" "$dest" "$move_old_files_to" "$options" "$(basename $0)" "$monitoring_URL"

The last line calls rclone_jobber.sh.
=source= and =dest= are required, the remaining arguments can be \"\" or undefined.

Rclone_jobber has 6 parameters, which are described in the next 6 sections:
1) source
2) dest
3) move_old_files_to
4) options
5) job_name
6) monitoring_URL

** 1) source
=source= is the directory to back up.

Example =source= argument:
: source="/home/wolfv"

** 2) dest
Data is backed up to =destination=$dest/last_snapshot=.

Example =dest= argument for [[https://rclone.org/local/][local file system]] data storage:
: dest="/media/wolfv/USB/wolfv_backup"

Example =dest= for remote data storage:
: dest="onedrive_wolfv_backup_crypt:"

** 3) move_old_files_to
When a file is changed or deleted, the old version already in backup is either moved or removed.
The =move_old_files_to= parameter specifies what happens to the old files.

*** move_old_files_to=\"dated_directory\"
Argument to move deleted or changed files to a dated directory:
: move_old_files_to="dated_directory" 

Old files are moved to the dated directory in their original hierarchy.
This makes it easy to restore a deleted sub-directory.
Also convenient to manually delete a directory from a previous year.
: backup
: ├── archive                       <<<<<<<< archive contains dated directories
: │   └── 2018
: │       ├── 2018-02-22_14:00:14
: │       │   └── direc1
: │       │       └── f1
: │       └── 2018-02-22_15:00:14   <<<<<<<< old files were moved here on dated_directory's date
: │           └── direc1
: │               └── f1            <<<<<<<< old version of file f1
: └── last_snapshot                 <<<<<<<< last_snapshot directory contains the most recent backup
:     └── direc1
:         └── f1

*** move_old_files_to=\"dated_files\"
Argument to move old files to old_files directory, and append move date to file names:
: move_old_files_to="dated_files"

Old files are moved to the old_files directory in their original hierarchy.
This is makes it easy to browse a file's history, and restore a particular version of a file.
: backup
: ├── last_snapshot                   <<<<<<<< last_snapshot directory contains the most recent backup
: │   └── direc1
: │       └── f1
: └── old_files                       <<<<<<<< old_files directory contains old dated_files
:     └── direc1
:         ├── f1_2018-02-22_14:00:14
:         └── f1_2018-02-22_15:00:14  <<<<<<<<< old version of file f1 moved here on appended date

*** move_old_files_to=\"\"
Argument to remove old files from backup:
: move_old_files_to=""

Only the most recent version of each file remains in the backup.
This can save a little storage space.
: backup
: └── last_snapshot         <<<<<<<< last_snapshot directory contains the most recent backup
:     └── direc1
:         └── f1            <<<<<<<< old versions of file f1 were overwritten or removed

** 4) options
The =options= argument can contain any number of rclone options.
You can put any [[https://rclone.org/docs/#options][rclone options]] in the options argument, except for these three:
: --backup-dir
: --suffix
: --log-file

Those options are set in rclone_jobber.sh.

Example options argument containing four rclone options:
: options="--filter-from=filter_rules --checksum --log-level=INFO --dry-run"

Rclone options used in this tutorial are:
- [[https://rclone.org/filtering/#filter-from-read-filtering-patterns-from-a-file][--filter-from]]  (discussed in the "filter rules" section)
- [[https://rclone.org/docs/#c-checksum][--checksum]]
- [[https://rclone.org/docs/#log-level-level][--log-level]]
- [[https://rclone.org/docs/#n-dry-run][--dry-run]]

** 5) job_name
The =job_name= argument specifies the job's file name:
: job_name="$(basename $0)"

The shell command "$(basename $0)" will fill in the job's file name for you.

Rclone_jobber guards against =job_name= running again before the previous run is finished.

Rclone_jobber prints =job_name= in warnings and log entries.

** 6) monitoring_URL
The =monitoring_URL= argument specifies a ping URL for a cron-monitoring service.

=monitoring_URL= is optional.
Some remote data-storage providers offer an integrated monitoring service, in which case =monitoring_URL= is not needed.

Example =monitoring_URL=:
: monitoring_URL="https://monitor.io/12345678-1234-1234-1234-1234567890ab"

Every time rclone_jobber.sh completes a job without error, it pings the monitoring_URL.
If the cron monitoring service hasn't been pinged within a set amount of time, then it sends you an email alert.
Many cron monitoring services offer free plans.

No two jobs should share the same =monitoring_URL=.

* Filter rules
Rclone has a sophisticated set of [[https://rclone.org/filtering/][filter rules]].
Filter rules tell rclone which files to include or exclude.

Open the [[./examples/filter_rules_exc][examples/filter_rules_exc]] file.
Each rule starts with a "+ " or "- ", followed by a pattern.
- a leading "+" means include if the pattern matches
- a leading "-" means exclude if the pattern matches

For each file in source, the filter rules are processed in the order that they are defined.
If the matcher fails to find a match after testing all the filter rules, then the path is included.

In the example filter_rules_exc file, each section starts with a ###### heading ######.
The sections alternate between include and exclude, progressing from fine to coarse grained.
This example has four sections, but any number of sections is possible.
[[./examples/filter_rules][examples/filter_rules]] has two sections.

The filter_rules_exc file is specified in the rclone_jobber =options= argument like this:
: options="--filter-from filter_rules_exc"

To see the example filter_rules_exc file in action, run:
: $ ~/rclone_jobber/examples/clear_USB_test_backup.sh
: $ ~/rclone_jobber/examples/job_backup_to_USB_exc.sh

* Select a cloud storage provider
All rclone cloud-storage providers are listed on https://rclone.org/.
Some of the cloud-storage-provider features are listed in two tables on https://rclone.org/overview/.

* Configure a remote
Once you have an account with your chosen cloud-storage provider, the next step is to configure its remote.

There is one page of configuration instructions for each cloud-storage provider.
Links to the configuration instructions are at https://rclone.org/docs/#configure and https://rclone.org/.
Follow the instructions to configure your remote now.

Rclone stores all the configuration information you entered in the default location ~/.config/rclone/rclone.conf.
The remote's password is stored in the rclone.conf file, so be careful about giving people access to it.

To list all your rclone remotes:
: $ rclone listremotes

To run the tutorial's example remote backup job on Linux, add this line to your ~/.profile file, but with your remote path:
: export remote="onedrive_test_rclone_backup"
and reload .profile:
: $ source ~/.profile

If you don't edit your .profile, you can edit the example scripts:
 replace occurrences of "${remote}" with your remote path.

To test your remote, run:
: $ ~/rclone_jobber/examples/job_backup_to_remote.sh

* Configure a crypt
"crypt" is a kind of remote that:
- encrypts and decrypts the data stream for an underlying remote
- performs encryption and decryption on client side
- uses the same command interface as other kinds of remotes

Instructions for configuring a crypt remote are at https://rclone.org/crypt/ and https://rclone.org/docs/#configuration-encryption.

When configuring a crypt remote, rclone will ask you to give it a name.
Put some thought into naming your remotes.
In this example, the crypt remote name is a concatenation of its underlying remote name, folder to encrypt, and "_crypt":
: name> myremote_myfolder_crypt

And then rclone will ask for the underlying remote.
This example will encrypt myfolder in myremote:
: remote> myremote:myfolder
You can always rename a remote later via rclone config.

To list all your rclone remotes:
: $ rclone listremotes

Most remote cloud-storage providers allow you to view your directory names and file names in a web browser.
But that's not very useful if the directory and file names were encrypted by rclone.
Use rclone to browse encrypted directory and file names.

To list directories in remote:
: $ rclone lsd remote:
: $ rclone lsd remote:path

To list objects and directories of path (requires rclone-v1.40 or later):
: $ rclone lsf remote:path

To list top-level files in path:
: $ rclone ls remote:path --max-depth 1 

To list all files in path recursively:
: $ rclone ls remote:path

[[./examples/job_backup_to_remote.sh][/examples/job_backup_to_remote.sh]] uses a remote, which could be of type crypt.

To test your crypt remote, set the path variable as described in the "Configure a remote" section, and then run:
: $ ~/rclone_jobber/examples/job_backup_to_remote.sh

*** pathIsTooLong error
Most cloud storage providers have a 254 character-path-length limit.
Crypt limits encrypted paths to 151 characters with some cloud storage providers (this is a [[https://github.com/ncw/rclone/issues/637][known crypt issue]]).
If the path is too long, rclone returns this ERROR:
: Failed to copy: invalidRequest: pathIsTooLong: Path exceeds maximum length

There are 3 work-a-rounds:
- turn off "enrcrypt directory names" in rclone config (file content can still be encrypted)
- shorten your paths
- Long Path Tool (I have not tried this)

*** Backblaze b2 lifecycle
rclone crypt file-name and directory-name encryption don’t work with Backblaze b2 lifecycle because:
- b2 lifecycle appends date to end of file names
- b2 doesn’t strip off the appended date before passing the file name back to rclone

So then rclone can’t decrypt the file names.

There are 3 work-a-rounds:
- turn off "enrcrypt file names" and "enrcrypt directory names" in rclone config (file content can still be encrypted)
- turn off b2 lifecycle, set move_old_files_to=\"dated_directory\" in backup job,
  and manually delete old files at end of life
- use a different remote data-storage provider

* Schedule backup jobs to run automatically
After the backup jobs are scheduled, you will have an automated back up system that follows this workflow:
1. a job scheduler calls a backup job script
2. the job script calls rclone_jobber.sh
3. rclone_jobber.sh calls rclone
4. rclone consults your filter rules, connects to a backup storage, and uploads files that have changed

Schedule your backup jobs in your favorite job scheduler.

The following example schedules jobs on cron (cron is a job scheduler installed on Linux).
The first line runs a local job every hour on the hour.
The second line runs a remote job every hour, 30 minutes past the hour.
The third line runs at 3:18 and 15:18 every day
: $ crontab -e
: 00 * * * * /home/wolfv/rclone_jobber/job_backup_to_USB.sh
: 30 * * * * /home/wolfv/rclone_jobber/job_backup_to_remote.sh
: 18 3,15 * * * /home/wolfv/rclone_jobber/job_backup_recovery_plan_to_remote.sh

The initial backup will take a long time (subsequent backups are much shorter).
If your computer goes to sleep while a backup is in progress, the backup will not finish.
Consider disabling sleep on your computer for the initial backup.
On Linux Gnome desktop:
: right click > Settings > Power > Automatic suspend: Off

* Logging options
The default behavior is to place rclone_jobber.log in the same directory as rclone_jobber.sh.
You can skip this section if you like the default logging.

Logging options are set in rclone_jobber.sh, headed by "# set log" comments.
To change logging behavior, search for "# set log" and change the default values.

Logging options are described in the next 5 sections.

** # set logging to verbose
To send more information to the log, use the send_to_log function in rclone_jobber.sh:
: # set logging to verbose
: send_to_log "$timestamp $job_name"
: send_to_log "$cmd"

Additionally, you can set [[https://rclone.org/docs/#log-level-level][--log-level]] in the job's "options" parameter.

** # set log_file path
In rclone_jobber.sh, variable log_file contains the log file's path.
You can change log_file to any path you like.
The default behavior is to place rclone_jobber.log in the same directory as rclone_jobber.sh:
: # set log_file path
: path="$(realpath "$0")"         #path of this script
: log_file="${path%.*}.log"       #replace path extension with "log"

** # set log_file path to /var/log/rclone_jobber.log (Linux)
To set the rclone_jobber log location to /var/log/, create the log file and give it the user's ownership and read-write permission.
In this example, rclone_jobber.log ownership is given to wolfv:
: $ sudo touch       /var/log/rclone_jobber.log
: $ sudo chown wolfv /var/log/rclone_jobber.log
: $ sudo chmod 0666  /var/log/rclone_jobber.log
: $ sudo ls -l       /var/log/rclone_jobber.log
: -rw-rw-rw-. 1 wolfv root 19 Mar 21 13:58 /var/log/rclone_jobber.log

In rclone_jobber.sh, set the new log_file path:
: # set log_file path
: log_file="/var/log/rclone_jobber.log"

** Logrotate /var/log/rclone_jobber.log (Linux)
Over time a log file can grow to unwieldy size.
The logrotate utility can automatically archive the current log, start a fresh log, and delete older logs.

To setup logrotate, set log_file path to /var/log/rclone_jobber.log (described in previous section).
Then create a logrotate configuration file in /etc/logrotate.d:
: $ sudo vi /etc/logrotate.d/rclone_jobber

And paste this text into the logrotate configuration file:
: /var/log/rclone_jobber.log {
: monthly
: rotate 2
: size 1M
: compress
: delaycompress
: }

More options are listed in man:
: $ man logrotate

Execute a dry-run to see what logrotate would do:
: $ logrotate -d /etc/logrotate.d/rclone_jobber

** Send /var/log/rclone_jobber.log to systemd journal (Linux)
Linux and macOS can send all log output to systemd journal.
To do so, make these two changes to rclone_jobber.sh script:
1. change log_option to --syslog
: # set log_option for rclone
: log_option="--syslog"
2. send msg to systemd journal (sending msg to log_file is optional, and is commented in this example)
:     # set log - send msg to log
:     #echo "$msg" >> "$log_file"                            #send msg to log_file
:     printf "$msg" | systemd-cat -t RCLONE_JOBBER -p info   #send msg to systemd journal

* Example backup jobs
The following system uses two backup jobs with complementary attributes (this is how I backup my home PC).
The latest snapshot can be easily restored from either backup.

[[./examples/job_backup_to_USB.sh][examples/job_backup_to_USB.sh]] has attributes that make it convenient to browse file history:
- local storage (for fast navigation)
- move_old_files_to=\"dated_files\" (old versions of a file are grouped together)
- not encrypted (brows files in a file manager) (unecrypted local storage is OK if storage is safe from theft, and useful if the remote storage password is lost)
- schedule hourly, on the hour (this assumes the USB drive is always plugged in and mounted)

[[./examples/job_backup_to_remote.sh][/examples/job_backup_to_remote.sh]] has attributes that make it secure, and easy to restore a deleted sub-directory:
- remote storage (off site is safe from on-site disaster)
- move_old_files_to=\"dated_directory\" (easy to restore a deleted sub-directory e.g. Documents)
- encrypted (please keep your password in a safe place)
- schedule hourly, 30 min past the hour (for a back up every 30 minutes when combined with job_backup_to_USB.sh)

In addition, job_backup_recovery_plan_to_remote.sh stores recovery-plan files off-site unecrypted.
Recovery-plan files are listed in the "Recovery plan" section.

Backup to both local and remote locations in case disaster destroys one.
If Internet connection fails, local backup is still made.

* Example restore-data
To restore data, copy files from backup to destination.

You can use cp (shell command) to restore data from local unecrypted backup:
- to copy a single file from local backup:
:    $ cp -p localBackupPath destPath
- to copy a last_snapshot from local backup:
:    $ cp -a localBackup/last_snapshot destPath

Use rclone to restore data from remote or encrypted backup:
- to copy a single file from remote backup:   rclone copy remote:sourcePath dest:destPath
- [[./examples/job_restore_last_snapshot.sh][examples/job_restore_last_snapshot.sh]]
- [[./examples/job_restore_directory_from_remote.sh][examples/job_restore_directory_from_remote.sh]]

* Test backup jobs and test restore-data jobs
The following commands test the example backup and restore jobs.
They test your entire data recovery system end to end, testing both the data backup and data recovery together.
Don't worry, the tutorial's environment is setup to make testing painless.

Clear and setup test directories in preparation for a new test run:
: $ ~/rclone_jobber/examples/clear_USB_test_backup.sh
: $ ~/rclone_jobber/examples/clear_remote_test_backup.sh
: $ ~/rclone_jobber/examples/setup_test_data_directory.sh

Back up data:
: $ ~/rclone_jobber/examples/job_backup_to_USB.sh
: $ ~/rclone_jobber/examples/job_backup_to_remote.sh

Open job_restore_last_snapshot.sh and edit source variable to restore data from, and save your edit.
Then restore data:
: $ ~/rclone_jobber/examples/job_restore_last_snapshot.sh

Verify that the files were faithfully restored:
: $ diff -r $HOME/test_rclone_data/direc0 /home/$USER/last_snapshot/direc0

Notice that rclone does not back up empty directories.

Follow a similar test procedure when you practice your recovery plan, but with real data.

* Recovery plan
Example recovery plan:
1. Retrieve recovery-plan files from on-site or off-site location
   - notes for installing OS
   - recovery plan (this file)
   - job_restore_last_snapshot.sh
   - ~/.config/rclone/rclone.conf
2. Install operating system
3. Install rclone
4. Restore ~/.config/rclone/rclone.conf
5. Edit source variable in job_restore_last_snapshot.sh, and then run job_restore_last_snapshot.sh

The rclone.conf configuration file should be in a secure location because it contains the encryption key for backup.
I keep my backup rclone.conf in a password manager (LastPass).
The other recovery-plan files (listed in item 1.) are not encrypted so that they can be accessed before rclone is installed.
With this setup, all I need to bootstrap the recovery process is a web browser and my LastPass master password.

Scheduling the backup of your backup recovery plan insures that your backup recovery-plan files are always up-to date.
The recovery-plan files should not be encrypted so that they can accessed before installing rclone.
For each backup location, place the recovery-plan files in a directory to be backed up.
- If a backup is not encrypted, then the recovery-plan files will be accessible in the backup.
- If a backup is encrypted, create an unecrypted backup job to the same underlying remote, like this example:
  -  [[rclone_jobber/examples/job_backup_recovery_plan_to_remote.sh][job_backup_recovery_plan_to_remote.sh]]
  -  [[rclone_jobber/examples/filter_rules_recovery_plan][filter_rules_recovery_plan]]
  -  and schedule job_backup_recovery_plan_to_remote.sh to run automatically

Practice the recovery plan.
Start from scratch with a blank environment (or use a different location on current machine).
You’ll run into snags, and that is the point.  Workout the snags BEFORE data is lost.
If you have enough disk space, restore all your data to a different directory, and then use diff to verify the accuracy of the restored data.

* Monitoring
** Check backups
Example monthly backup check.

For each backup job:
- check that recently changed files are in the backup
:    $ ls -l /media/wolfv/big_stick/wolfv_backup/last_snapshot/Documents/tasks/tasks.org
:    $ rclone lsl onedrive_wolfv_backup_crypt:last_snapshot/Documents/tasks --max-depth 1
- check space usage and available space
- check rclone_jobber.log
:    $ cat /var/log/rclone_jobber.log
- make sure monitoring URLs are still active

Do not rely solely on warning messages or rclone_jobber.log for monitoring; they do not prove that data was saved to destination.
Check each backup job as described above.

** Check recovery plan
Example yearly recovery-plan check:
1. review your recovery plan
2. make sure the recovery-plan files are still accessible and up-to date (listed in "Recovery plan" section)
   - on site copy
   - off site copy
3. practice restore-data on small test directory, from ~/rclone_jobber/examples:
    1. setup_test_data_directory.sh
    2. job_backup_to_USB.sh
    3. job_backup_to_remote.sh
    4. delete the ~/test_data_directory
    5. job_restore_last_snapshot.sh

* License
[[http://creativecommons.org/licenses/by-nc-sa/4.0/][https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png]]\\
rclone_jobber_tutorial.org by Wolfram Volpi is licensed under a [[http://creativecommons.org/licenses/by-nc-sa/4.0/][Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License]].
Based on a work at https://github.com/wolfv6/rclone_jobber.
Permissions beyond the scope of this license may be available at https://github.com/wolfv6/rclone_jobber/issues.

Rclone_jobber is not affiliated with rclone.
